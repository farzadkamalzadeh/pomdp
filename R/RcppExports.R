# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

reward_val_from_df_cpp <- function(model, action, start_state, end_state, observation) {
    .Call(`_pomdp_reward_val_from_df_cpp`, model, action, start_state, end_state, observation)
}

reward_alpha_cpp <- function(alpha, belief) {
    .Call(`_pomdp_reward_alpha_cpp`, alpha, belief)
}

reward_cpp <- function(model, belief) {
    .Call(`_pomdp_reward_cpp`, model, belief)
}

update_belief_cpp <- function(model, belief, action, observation, digits = 7L) {
    .Call(`_pomdp_update_belief_cpp`, model, belief, action, observation, digits)
}

round_stochastic_cpp <- function(x, digits) {
    .Call(`_pomdp_round_stochastic_cpp`, x, digits)
}

veccrossprod <- function(A, b) {
    .Call(`_pomdp_veccrossprod`, A, b)
}

vecprod <- function(A, b) {
    .Call(`_pomdp_vecprod`, A, b)
}

sample_simplex_cpp <- function(n, states, projection) {
    .Call(`_pomdp_sample_simplex_cpp`, n, states, projection)
}

simulate_MDP_cpp <- function(model, n, start, horizon, disc = 1.0, return_trajectories = FALSE, epsilon = 1.0, verbose = FALSE) {
    .Call(`_pomdp_simulate_MDP_cpp`, model, n, start, horizon, disc, return_trajectories, epsilon, verbose)
}

simulate_POMDP_cpp <- function(model, n, belief, horizon, disc = 1.0, return_beliefs = FALSE, return_trajectories = FALSE, epsilon = 1.0, digits = 7L, verbose = FALSE) {
    .Call(`_pomdp_simulate_POMDP_cpp`, model, n, belief, horizon, disc, return_beliefs, return_trajectories, epsilon, digits, verbose)
}

