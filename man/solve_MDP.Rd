% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/solve_MDP.R
\name{solve_MDP}
\alias{solve_MDP}
\alias{random_policy}
\title{Solve an MDP Problem}
\usage{
solve_MDP(
  model,
  eps = 0.01,
  horizon = NULL,
  discount = NULL,
  max_iterations = 1000,
  policy_eval_n = 10,
  method = "value",
  verbose = FALSE
)

random_policy(model, prob = NULL)
}
\arguments{
\item{model}{a POMDP problem specification created with \code{\link[=POMDP]{POMDP()}}.
Alternatively, a POMDP file or the URL for a POMDP file can be specified.}

\item{eps}{maximum error allowed in the utility of any state
(i.e., the maximum policy loss).}

\item{horizon}{an integer with the number of epochs for problems with a
finite planning horizon. If set to \code{Inf}, the algorithm continues
running iterations till it converges to the infinite horizon solution. If
\code{NULL}, then the horizon specified in \code{model} will be used.  For
time-dependent POMDPs a vector of horizons can be specified (see Details
section).}

\item{discount}{discount factor in range \eqn{[0, 1]}. If \code{NULL}, then the
discount factor specified in \code{model} will be used.}

\item{max_iterations}{maximum number of iterations to converge. If the
maximum is reached then the non-converged solution is returned with a
warning.}

\item{policy_eval_n}{number of iterations used for the approximate policy evaluation in method \code{'policy'} iteration.}

\item{method}{string; one of the following solution methods: \code{'value'},
\code{'policy'}.}

\item{verbose}{logical, if set to \code{TRUE}, the function provides the
output of the pomdp solver in the R console.}

\item{prob}{probability vector for actions.}
}
\value{
The solver returns an object of class POMDP which is a list with the
model specifications (\code{model}), the solution (\code{solution}).
}
\description{
A simple implementation of value iteration and modified policy iteration.
}
\examples{
data(Maze)
Maze

# use value iteration
maze_solved <- solve_MDP(Maze, method = "value")
policy(maze_solved)

plot_value_function(maze_solved)

maze_solved <- solve_MDP(Maze, method = "policy")
policy(maze_solved)
}
\author{
Michael Hahsler
}
